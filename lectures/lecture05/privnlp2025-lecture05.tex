% !TeX program = lualatex
% !BIB program = biber
% Lualatex is important to render TTF fonts; with pdflatex it's just the regular one
% ratio 16:9 -- https://tex.stackexchange.com/questions/14336/

% compile two versions, inspired by https://tex.stackexchange.com/a/1501
% use the script "compile-pdf.sh"
\newif\ifhandout
% if flags.tex does not exist, create an empty file to be able to compile in TeXstudio
\input{flags}

\ifhandout
\documentclass[12pt,aspectratio=169,handout]{beamer}
\else
\documentclass[12pt,aspectratio=169]{beamer}
\fi


\input{header-include.tex}



\title{Privacy-Preserving Natural Language Processing}
\subtitle{Lecture 5 -- Local DP and Randomized Response}
\date{May 15, 2025}
\author{Prof.\ Dr.\ Ivan Habernal}
\institute{
\texttt{www.trusthlt.org} \\
Chair of Trustworthy Human Language Technologies (TrustHLT) \\
Ruhr University Bochum \& Research Center Trustworthy Data Science and Security}

\begin{document}

\maketitle


\section{Recap}


\begin{frame}{What we covered so far}

\begin{itemize}
\item For provably private data analysis we need randomized algorithms
\item Central (with a trusted curator) pure $(\varepsilon, 0)$ differential privacy
\item Laplace mechanism: numeric queries, $\ell_1$ sensitivity, 
\item Exponential mechanism: `any-range' queries (arbitrary sets), utility function and its sensitivity
\end{itemize}


%A randomized algorithm (mechanism) $\mathcal{M}$ is $(\varepsilon, 0)$-\textbf{differentially private} if for any two neighboring datasets $D, D'$ and any output $\mathcal{Y} \subseteq \mathcal{Z}$ this guarantee holds:
%$$
%\Pr[\mathcal{M}(D) \in \mathcal{Y}] \leq \exp(\varepsilon) \Pr[\mathcal{M}(D') \in \mathcal{Y}]
%$$

%\begin{tikzpicture}[overlay, remember picture]
%\node at (current page.north east)[ref] {
%\fullcite[Definition~2.4]{Dwork.Roth.2013} \par};
%\end{tikzpicture}

\end{frame}

\begin{frame}{Today}

\begin{itemize}
\item $\ldots$
\item Central (with a \textbf{trusted curator}) pure $(\varepsilon, 0)$ differential privacy
\item $\ldots$
\end{itemize}

What if we don't trust anyone?

%\begin{tikzpicture}[overlay, remember picture]
%\node at (current page.north east)[ref] {
%\fullcite[Definition~2.4]{Dwork.Roth.2013} \par};
%\end{tikzpicture}

\end{frame}


\section{Math refresher}

\begin{frame}{Bernoulli trial (Bernoulli distribution, Bernoulli R.V., etc.)}

Suppose that we run an experiment that succeeds with probability $\theta$ and fails with probability $1 - \theta$

A Bernoulli (or an indicator) random variable $Y$ has the following probability distribution on $k \in \{0, 1\}$

$\Pr(Y = 1) = \theta$

$\Pr(Y = 0) = 1 - \theta$

which can be also expressed as

$\Pr(Y = k)=p^{k}(1-\theta)^{1-k}$
\end{frame}


\section{Local differential privacy}

\begin{frame}{Motivation}

The notion of neighboring datasets revisited

-- size 1, replacing one person

Can we ask numeric queries on database of size 1?

Sure!

Example query: How many classes did you skip (and binge-watched Netflix instead)?

True value: between 0 and 15

You just need the $\ell_1$ sensitivity for Laplace mechanism, decide on the $\varepsilon$ and report

\end{frame}


\begin{frame}{DP enables learning about population, not individuals!}
What I'm really interested in is some statistics, e.g., the average number of lectures skipped across all students.

But `privatizing' the `raw' values shown previously removes the need for a trusted curator.

It comes with extra price (to be discussed later)

\end{frame}


Now we know that we can privately (DP) answer statistical queries without a trusted curator

Let's simplify our example even more


\begin{frame}{Reporting single bit}
Each person has a secret bit, e.g. "I took illegal drugs"


The query I might be interested in is `What percentage of students take illegal drugs'

\end{frame}



\begin{frame}{How to report a single bit}

From true value to reported value

Two extremes

\pause

\begin{itemize}
\item Just report the true value
\item Completely random answer (e.g., toss a coin)
\end{itemize}

Something between these two extremes

\end{frame}




\begin{frame}{How to report a single bit}

From true value to reported value

Idea: Report the true value with some probability, `flip' and report otherwise

How to do the above `with some probability' exactly?

Again: Use a randomized algorithm!

\begin{itemize}
\item Step 1: Draw a random value, either 0 or 1, from a Bernoulli distribution
\item Step 2: If 1, report true value, if 0 report flipped value
\end{itemize}

(1 is usually associated with `true' or `success' and 0 with `false' or `failure')

\end{frame}


\begin{frame}{How to parametrize this Bernoulli distribution?}

\begin{itemize}
\item Step 1: Draw a random value, either 0 or 1, from a Bernoulli distribution
\item Step 2: If 1, report true value, if 0 report flipped value
\end{itemize}

What $\theta$ would we need for modeling the extremes? (by the way: $\theta$ is publicly known! No `security through obscurity'!)

Extreme 1: \emph{Just report the true value}

\pause

$\mathrm{Ber}(\theta = 1)$ always returns 1 $\rightarrow$ always true value (no privacy)

Extreme 2: \emph{Completely random answer}

\pause

$\mathrm{Ber}(\theta = 0.5)$ completely random $\rightarrow$ no matter what the raw value is, this is equivalent to reporting a random value

%\pause
%Wrong answer:
%$\mathrm{Ber}(\theta = 0)$ always returns 0 $\rightarrow$ always the opposite of true (no privacy)


\end{frame}

\begin{frame}{How to parametrize this Bernoulli distribution?}

We saw that $\theta$ controls the privacy strength and want

$0.5 < \theta < 1.0$

where $0.5 \leftarrow \theta$ --- more privacy

and $\theta \rightarrow 1.0$ --- less privacy


How do we control privacy strength in DP?

$0 \leftarrow \varepsilon$ --- more privacy

$\varepsilon \rightarrow \infty$ --- less privacy

We need to find a function that maps $\varepsilon$ to $\theta$ (and also satisfies DP)
\end{frame}



\begin{frame}{First attempt}

We want $0.5 < \theta < 1.0$ as a function of $0 \leq \varepsilon \leq \infty$

$\lim_{\varepsilon \to \infty} 1 = 1$
so does
$\lim_{\varepsilon \to \infty} \frac{\varepsilon}{\varepsilon} = 1$
as well as
$\lim_{\varepsilon \to \infty} \frac{\varepsilon}{\varepsilon + 1} = 1$

But it doesn't work for $\lim_{\varepsilon \to 0}$ yet because $\lim_{\varepsilon \to 0} \frac{\varepsilon}{\varepsilon + 1} \neq 0.5$

The easiest fix: Just add 1!

$\lim_{\varepsilon \to 0} \frac{\varepsilon + 1}{\varepsilon + 1 + 1} = 0.5$ and $\lim_{\varepsilon \to \infty} \frac{\varepsilon + 1}{\varepsilon + 1 + 1} = 1$

So let's try with $\theta = \frac{\varepsilon + 1}{\varepsilon + 2}$


\end{frame}



\begin{frame}{Try to prove DP with our Bernoulli trial}

For any `neighboring' $D, D' \in \{0, 1\}$ and any $y \in \{0, 1\}$ the $\varepsilon$-DP definition must hold:
$$
\frac{
	\Pr(\mathcal{M}(D) = y)
}{
	\Pr(\mathcal{M}(D') = y)
} \leq \exp(\varepsilon)
$$


So let's try with Bernoulli trail and report the true with probability $\theta = \frac{\varepsilon + 1}{\varepsilon + 2}$ (and flip with probability  $1 - \theta$)

\end{frame}



\begin{frame}{Try to prove DP with our Bernoulli trial}

For any `neighboring' $D, D' \in \{0, 1\}$ and any $y \in \{0, 1\}$ the $\varepsilon$-DP definition must hold:
$$
\frac{
	\Pr(\mathcal{M}(D) = y)
}{
	\Pr(\mathcal{M}(D') = y)
} \leq \exp(\varepsilon)
$$


So let's try with Bernoulli trail and report the true with probability $\theta = \frac{\varepsilon + 1}{\varepsilon + 2}$ (and flip with probability  $1 - \theta$)

\end{frame}



\begin{frame}

Let $D = 0, D' = 1, y = 0$ ($D'$ flipped from 1 to 0):
$$
\begin{aligned}
\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} &=
\frac{\theta}{1 - \theta}
=
\frac{
\frac{\varepsilon + 1}{\varepsilon + 2}
}{
	1 - \frac{\varepsilon + 1}{\varepsilon + 2}
}
=
\frac{
\frac{\varepsilon + 1}{\varepsilon + 2}
}{
\frac{\varepsilon + 2 - (\varepsilon + 1)}{\varepsilon + 2}
}
=
\frac{\varepsilon + 1}{\varepsilon + 2}
\cdot
\frac{\varepsilon + 2}{1}
\\
&=
\varepsilon + 1
\leq \exp(\varepsilon)
\end{aligned}
$$
The same holds also for $D = 1, D' = 0, y = 1$ ($D'$ flipped). For not flipping, the ratio is 1, so the inequality also holds!

Great! We designed a DP algorithm for reporting a single bit (locally)

But can we do any better (with better utility?)

\end{frame}





\begin{frame}{Improving the inequality}

\begin{block}{Our first attempt}
$\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} =
\frac{\theta}{1 - \theta} =
\frac{
\frac{\varepsilon + 1}{\varepsilon + 2}
}{
	1 - \frac{\varepsilon + 1}{\varepsilon + 2}
}
=
\varepsilon + 1
\leq \exp(\varepsilon)$
\end{block}

We can approximate $\exp(\varepsilon)$ with a line around 0

$\exp(\varepsilon) \geq 1 + \varepsilon$

but also with a polynom of degree two

$\exp(\varepsilon) \geq 1 + \varepsilon + \frac{\varepsilon^2}{2}$

We get equality with the very definition of using power series
$$\exp(\varepsilon) := \sum_{k = 0}^{\infty} \frac{x^k}{k!}$$
\end{frame}


\begin{frame}{Improving the inequality}

\begin{block}{Our first attempt}
$\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} =
\frac{\theta}{1 - \theta} =
\frac{
\frac{\varepsilon + 1}{\varepsilon + 2}
}{
	1 - \frac{\varepsilon + 1}{\varepsilon + 2}
}
=
\varepsilon + 1
\leq \exp(\varepsilon)$
\end{block}

What if we replace $\varepsilon + 1$ with $\exp(\varepsilon)$ and worked it out backwards?


\begin{block}{Our second attempt}
$\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} =
\frac{\theta}{1 - \theta} =
\ldots ? \ldots
=
\exp(\varepsilon)
\leq \exp(\varepsilon)$
\end{block}


\end{frame}






\begin{frame}{Second attempt: Replace $\varepsilon + 1$ with $\exp(\varepsilon)$ backwards}

\begin{block}{First attempt recap (now rewriting with $2 = 1 + 1$)}
$$
\begin{aligned}
\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} &=
\frac{
\frac{\varepsilon + 1}{\varepsilon + 1 + 1}
}{
	1 - \frac{\varepsilon + 1}{\varepsilon + 1 + 1}
}
=
\frac{
\frac{\varepsilon + 1}{\varepsilon + 1 + 1}
}{
\frac{\varepsilon + 1 + 1 - (\varepsilon + 1)}{\varepsilon + 1 + 1}
}\\
&=
\frac{\varepsilon + 1}{\varepsilon + 1 + 1}
\cdot
\frac{\varepsilon + 1 + 1}{1}
=
\varepsilon + 1
\leq \exp(\varepsilon)
\end{aligned}
$$
\end{block}
\vspace{-1em}
$$
\begin{aligned}
\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} &=
\frac{
\frac{ \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
}{
	1 - \frac{ \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
}
=
\frac{
\frac{ \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
}{
\frac{ \exp(\varepsilon) + 1 -  \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
}\\
&=
\frac{ \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
\cdot
\frac{ \exp(\varepsilon) + 1}{1}
=
\exp(\varepsilon)
\leq \exp(\varepsilon)
\end{aligned}
$$
\end{frame}





\begin{frame}{Second attempt: Replace $\varepsilon + 1$ with $\exp(\varepsilon)$ backwards}

\begin{block}{We found the tightest $\theta$}
$$
\frac{\Pr(y = 0 | D = 0)}{\Pr(y = 0 | D' = 1)} =
\frac{\theta}{1 - \theta} =
\frac{
\frac{ \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
}{
	1 - \frac{ \exp(\varepsilon)}{ \exp(\varepsilon) + 1}
}
\underbrace{\leq}_{\text{(actually } = \text{)}}
\exp(\varepsilon)
$$
\end{block}


Recap our algorithm:

\begin{itemize}
\item Step 1: Draw a random value, either 0 or 1, from a Bernoulli distribution
\item Step 2: If 1, report true value, if 0 report flipped value
\end{itemize}

We found that $\theta = \frac{\exp(\varepsilon)}{\exp(\varepsilon) + 1} = \frac{1}{1 + \exp(- \varepsilon)}$ makes our algorithm $(\varepsilon, 0)$-DP


\end{frame}


\begin{frame}{We discovered the "Randomized response" algorithm}

\begin{itemize}
\item Step 1: Draw a random value, either 0 or 1, from a Bernoulli distribution
\item Step 2: If 1, report true value, if 0 report flipped value
\end{itemize}

Parametrize Bernoulli with $\theta = \frac{\exp(\varepsilon)}{\exp(\varepsilon) + 1} = \frac{1}{1 + \exp(- \varepsilon)}$

Homework: Prove that Randomized response is $(\varepsilon, 0)$-DP (just do what we did for any pair of $D, D', y$)


\end{frame}





\begin{frame}{We discovered the "Randomized response" algorithm}

\begin{itemize}
\item Step 1: Draw a random value, either 0 or 1, from a Bernoulli distribution
\item Step 2: If 1, report true value, if 0 report flipped value
\end{itemize}

Parametrize Bernoulli with $\theta = \frac{\exp(\varepsilon)}{\exp(\varepsilon) + 1} = \frac{1}{1 + \exp(- \varepsilon)}$

Homework: Prove that Randomized response is $(\varepsilon, 0)$-DP (just do what we did for any pair of $D, D', y$)


\end{frame}


\begin{frame}{Summary}

Local DP: No trusted curator needed

Enables privatize raw data and publish with plausible deniability

Randomized response: Known and used since the 1960's

Relevance to NLP: Publishing data for training (but comes with a cost)

\end{frame}




\begin{frame}{License and credits}

	\begin{columns}
		\begin{column}{0.7\textwidth}
			Licensed under Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)
		\end{column}
		\begin{column}{0.2\textwidth}
			\includegraphics[width=0.9\linewidth]{img/cc-by-sa-icon.pdf}
		\end{column}
	\end{columns}
	
	\bigskip
	
	Credits
	
	\begin{scriptsize}
		
		Ivan Habernal
		
		Content from ACL Anthology papers licensed under CC-BY \url{https://www.aclweb.org/anthology}
		
		Partly inspired by lectures from Antti Honkela, Aurélien Bellet, Gautam Kamath
	
	\end{scriptsize}
	
\end{frame}



\end{document}

