
@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}
@inproceedings {carlini2021dea,
author = {Nicholas Carlini and Florian Tram{\`e}r and Eric Wallace and Matthew Jagielski and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown and Dawn Song and {\'U}lfar Erlingsson and Alina Oprea and Colin Raffel},
title = {Extracting Training Data from Large Language Models},
booktitle = {30th USENIX Security Symposium (USENIX Security 21)},
year = {2021},
isbn = {978-1-939133-24-3},
pages = {2633--2650},
url = {https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting},
publisher = {USENIX Association},
month = {08}
}

@inproceedings{carlini2023dea,
title={Quantifying Memorization Across Neural Language Models},
author={Nicholas Carlini and Daphne Ippolito and Matthew Jagielski and Katherine Lee and Florian Tramer and Chiyuan Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=TatRHT_1cK}
}
@inproceedings{carlini2019dea,
author = {Carlini, Nicholas and Liu, Chang and Erlingsson, \'{U}lfar and Kos, Jernej and Song, Dawn},
title = {The secret sharer: evaluating and testing unintended memorization in neural networks},
year = {2019},
isbn = {9781939133069},
publisher = {USENIX Association},
address = {USA},
booktitle = {Proceedings of the 28th USENIX Conference on Security Symposium},
pages = {267–284},
numpages = {18},
location = {Santa Clara, CA, USA},
series = {SEC'19}
}


@inproceedings{jia2022badencoder,
  title={Badencoder: Backdoor attacks to pre-trained encoders in self-supervised learning},
  author={Jia, Jinyuan and Liu, Yupei and Gong, Neil Zhenqiang},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={2043--2059},
  year={2022},
  organization={IEEE}
}

@article{zhao2025a,
    title={A Survey of Recent Backdoor Attacks and Defenses in Large Language Models},
    author={Shuai Zhao and Meihuizi Jia and Zhongliang Guo and Leilei Gan and XIAOYU XU and Xiaobao Wu and Jie Fu and Feng Yichao and Fengjun Pan and Anh Tuan Luu},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2025},
    url={https://openreview.net/forum?id=wZLWuFHxt5},
    note={Survey Certification}
}

@article{zhou2024learning,
  author = {Zhou, Xiangyu and Qiang, Yao and Zare Zade, Saleh and Roshani, Mohammad Amin and Khanduri, Prashant and Zytko, Douglas and Zhu, Dongxiao},
  title = {Learning to Poison Large Language Models During Instruction Tuning},
  booktitle={Submitted to ACL Rolling Review - May 2025},
  journal = {arXiv e-prints},
  volume = {abs/2402.13459},
  year = {2024},
  url = {https://doi.org/10.48550/arXiv.2402.13459}
}

@inproceedings{alan2023ba,
author = {Wan, Alexander and Wallace, Eric and Shen, Sheng and Klein, Dan},
title = {Poisoning language models during instruction tuning},
year = {2023},
publisher = {JMLR.org},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1474},
numpages = {13},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@inproceedings{wallace2021concealed,
  title       = {Concealed Data Poisoning Attacks on {NLP} Models},
  author      = {Wallace, Eric and Zhao, Tony and Feng, Shi and Singh, Sameer},
  editor      = {
    Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer, Luke and
    Hakkani-Tur, Dilek and Beltagy, Iz and Bethard, Steven and
    Cotterell, Ryan and Chakraborty, Tanmoy and Zhou, Yichao
  },
  booktitle   = {Proceedings of the 2021 Conference of the North American Chapter 
                 of the Association for Computational Linguistics: Human Language Technologies},
  month       = jun,
  year        = {2021},
  address     = {Online},
  publisher   = {Association for Computational Linguistics},
  pages       = {139--150},
  url         = {https://aclanthology.org/2021.naacl-main.13/},
  doi         = {10.18653/v1/2021.naacl-main.13},
}
@inproceedings{rlhfpoison2024wang,
    title = {RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models},
    author = {Wang, Jiongxiao and Wu, Junlin and Chen, Muhao and Vorobeychik, Yevgeniy and Xiao, Chaowei},
    editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
    booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month = aug,
    year = {2024},
    address = {Bangkok, Thailand},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2024.acl-long.140/},
    doi = {10.18653/v1/2024.acl-long.140},
    pages = {2551--2570},
}


@misc{wang2025pia,
      title={Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs}, 
      author={Jiawen Wang and Pritha Gupta and Ivan Habernal and Eyke Hüllermeier},
      year={2025},
      eprint={2505.14368},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2505.14368}, 
}